# Transformer Model Implementation in PyTorch
ä»é›¶å¼€å§‹å®ç°çš„é€šç”¨ Transformer æ¨¡å‹ï¼Œå¯ç”¨äºå¤„ç†å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ã€‚ï¼ˆæœ¬é¡¹ç›®åœ¨tinyshakespeareæ•°æ®é›†ä¸Šè®­ç»ƒç”¨äºæ¨¡ä»¿ç”Ÿæˆæ–‡æœ¬ï¼‰

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- **ä»é›¶å®ç°**: æ ¸å¿ƒ Transformer ç»„ä»¶ï¼ˆå¦‚ `MultiHeadAttention`, `PositionalEncoding`, `EncoderBlock`, `DecoderBlock`ï¼‰å‡ä»é›¶å¼€å§‹ç¼–å†™ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹ã€‚
- **å¤šä»»åŠ¡æ”¯æŒ**: æ¶æ„è®¾è®¡çµæ´»ï¼Œé€šè¿‡é…ç½®æ–‡ä»¶å¯è½»æ¾åˆ‡æ¢ä¸åŒçš„ NLP ä»»åŠ¡ï¼š
  - **è¯­è¨€å»ºæ¨¡ (Language Modeling)**: ç±»ä¼¼ GPT çš„ä»…è§£ç å™¨ï¼ˆDecoder-Onlyï¼‰æ¨¡å¼ï¼Œç”¨äºæ–‡æœ¬ç”Ÿæˆã€‚
  - **åºåˆ—åˆ°åºåˆ— (Sequence-to-Sequence)**: å®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆEncoder-Decoderï¼‰æ¶æ„ï¼Œç”¨äºæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ã€‚
  - **æ–‡æœ¬åˆ†ç±» (Text Classification)**: ï¼ˆéœ€åœ¨æ¨¡å‹ä¸­æ·»åŠ åˆ†ç±»å¤´ï¼‰æ•°æ®åŠ è½½æµç¨‹å·²æ”¯æŒã€‚
- **å¯é…ç½®**: é€šè¿‡ `src/config.py` æ–‡ä»¶å¯ä»¥è½»æ¾å®šä¹‰å’Œåˆ‡æ¢ä¸åŒçš„æ¨¡å‹è¶…å‚æ•°ã€æ•°æ®é›†å’Œè®­ç»ƒè®¾ç½®ã€‚
- **é«˜çº§è®­ç»ƒç‰¹æ€§**:
  - æ”¯æŒä»æ£€æŸ¥ç‚¹**æ¢å¤è®­ç»ƒ**ã€‚
  - é›†æˆ **Cosine Annealing å­¦ä¹ ç‡è°ƒåº¦å™¨**ã€‚
  - è‡ªåŠ¨å°†è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡ï¼ˆLoss, Perplexity, Learning Rateï¼‰è®°å½•åˆ° `training_metrics.csv`ã€‚
- **æ–‡æœ¬ç”Ÿæˆ**: `eval.py` è„šæœ¬æ”¯æŒä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¹¶é›†æˆäº†**æ¸©åº¦ï¼ˆTemperatureï¼‰**å’Œ **Top-K é‡‡æ ·**ç­–ç•¥ã€‚
- **ç»“æœå¯è§†åŒ–**: `results/plot_metrics.py` è„šæœ¬å¯ä»¥ä¸€é”®å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡ç»˜åˆ¶æˆå›¾è¡¨ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ data/                     # (å»ºè®®) å­˜æ”¾æœ¬åœ°æ•°æ®é›†
â”‚   â””â”€â”€ tinyshakespeare.txt
â”œâ”€â”€ results/                  # å­˜æ”¾ç»“æœå’Œå›¾è¡¨
â”‚   â”œâ”€â”€ plot_metrics.py       # ç»˜å›¾è„šæœ¬
â”‚   â””â”€â”€ training_curves.png   # ç”Ÿæˆçš„å›¾è¡¨
â”œâ”€â”€ src/                      # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ config.py             # ä»»åŠ¡å’Œæ¨¡å‹é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ dataset_utils.py      # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”‚   â””â”€â”€ model.py              # Transformer æ¨¡å‹å®šä¹‰
â”œâ”€â”€ train.py                  # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ eval.py                   # è¯„ä¼°å’Œæ–‡æœ¬ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ best_model_checkpoint.pt  # è®­ç»ƒä¸­ä¿å­˜çš„æœ€ä½³æ¨¡å‹
â”œâ”€â”€ training_metrics.csv      # è®­ç»ƒæŒ‡æ ‡æ—¥å¿—
â””â”€â”€ requirements.txt          # é¡¹ç›®ä¾èµ–
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®

é¦–å…ˆï¼Œå…‹éš†æœ¬ä»“åº“å¹¶è¿›å…¥é¡¹ç›®ç›®å½•ï¼š
```bash
git clone <your-repo-url>
cd transformer-project
```

å»ºè®®ä½¿ç”¨ Conda æˆ– venv åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ Python ç¯å¢ƒï¼š
```bash
# ä½¿ç”¨ Conda
conda create -n transformer_env python=3.8
conda activate transformer_env

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate    # Windows
```

ç„¶åï¼Œå®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–é¡¹ï¼š
```bash
pip install -r requirements.txt
```

### 2. è®­ç»ƒæ¨¡å‹

ä½¿ç”¨ `train.py` è„šæœ¬å¼€å§‹è®­ç»ƒã€‚ä½ å¯ä»¥é€šè¿‡ `--config` å‚æ•°é€‰æ‹©ä¸€ä¸ªé¢„å®šä¹‰çš„é…ç½®ï¼ˆä¾‹å¦‚ `tiny_shakespeare`ï¼‰ã€‚

**å¼€å§‹ä¸€æ¬¡æ–°è®­ç»ƒ:**
```bash
# åœ¨ç¬¬ä¸€ä¸ªå¯ç”¨ GPU ä¸Šè®­ç»ƒ
python train.py --config tiny_shakespeare
```

**æŒ‡å®š GPU å¹¶è®¾ç½®æ€»è½®æ¬¡:**
```bash
# åœ¨ 1 å· GPU ä¸Šè®­ç»ƒ 200 è½®
CUDA_VISIBLE_DEVICES=1 python train.py --config tiny_shakespeare --epochs 200
```

**ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ:**
```bash
CUDA_VISIBLE_DEVICES=1 python train.py --config tiny_shakespeare --resume --epochs 300
```

### 3. è¯„ä¼°ä¸æ–‡æœ¬ç”Ÿæˆ

è®­ç»ƒå®Œæˆåï¼Œ`best_model_checkpoint.pt` æ–‡ä»¶ä¼šè¢«ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ã€‚è¿è¡Œ `eval.py` æ¥åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆæ–‡æœ¬ã€‚
```bash
python eval.py
```
ä½ å¯ä»¥ç›´æ¥åœ¨ `eval.py` è„šæœ¬çš„ `if __name__ == "__main__"` éƒ¨åˆ†ä¿®æ”¹èµ·å§‹æ–‡æœ¬ã€ç”Ÿæˆé•¿åº¦å’Œé‡‡æ ·å‚æ•°ã€‚

### 4. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

è¿è¡Œ `plot_metrics.py` è„šæœ¬æ¥å°† `training_metrics.csv` ä¸­çš„æ•°æ®ç»˜åˆ¶æˆå›¾è¡¨ã€‚
```bash
python results/plot_metrics.py
```
ç”Ÿæˆçš„ `training_curves.png` å›¾åƒå°†è¢«ä¿å­˜åœ¨ `results/` ç›®å½•ä¸‹ã€‚

## ğŸ”§ é¢„ç½®é…ç½®

é¡¹ç›®ä¸­é¢„ç½®äº†ä»¥ä¸‹é…ç½®ï¼Œå¯åœ¨ `src/config.py` ä¸­æŸ¥çœ‹å’Œä¿®æ”¹ï¼š

- `tiny_shakespeare`: ç”¨äºå­—ç¬¦çº§è¯­è¨€å»ºæ¨¡ã€‚
- `iwslt2017`: ç”¨äºè‹±å¾·æœºå™¨ç¿»è¯‘ã€‚
- `ag_news`: ç”¨äºæ–°é—»æ–‡æœ¬åˆ†ç±»ã€‚
```

---

### `requirements.txt`

è¿™ä¸ªæ–‡ä»¶åˆ—å‡ºäº†é¡¹ç›®è¿è¡Œæ‰€éœ€çš„æ‰€æœ‰ Python åº“ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ `pip install -r requirements.txt` ä¸€é”®å®‰è£…ã€‚

````text
// filepath: f:\transformer-project\requirements.txt
# Core deep learning framework
torch
torchvision
torchaudio

# Hugging Face libraries for datasets and tokenizers
datasets
transformers

# Utilities
tqdm         # Progress bars
requests     # For downloading data if needed

# For plotting results
pandas
matplotlib
```// filepath: f:\transformer-project\README.md
# Transformer Model Implementation in PyTorch

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ PyTorch ä»é›¶å¼€å§‹å®ç°çš„é€šç”¨ Transformer æ¨¡å‹ã€‚è¯¥é¡¹ç›®æ—¨åœ¨æä¾›ä¸€ä¸ªæ¸…æ™°ã€å¯é…ç½®ä¸”çµæ´»çš„ Transformer æ¶æ„ï¼Œå¯ç”¨äºå¤„ç†å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- **ä»é›¶å®ç°**: æ ¸å¿ƒ Transformer ç»„ä»¶ï¼ˆå¦‚ `MultiHeadAttention`, `PositionalEncoding`, `EncoderBlock`, `DecoderBlock`ï¼‰å‡ä»é›¶å¼€å§‹ç¼–å†™ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹ã€‚
- **å¤šä»»åŠ¡æ”¯æŒ**: æ¶æ„è®¾è®¡çµæ´»ï¼Œé€šè¿‡é…ç½®æ–‡ä»¶å¯è½»æ¾åˆ‡æ¢ä¸åŒçš„ NLP ä»»åŠ¡ï¼š
  - **è¯­è¨€å»ºæ¨¡ (Language Modeling)**: ç±»ä¼¼ GPT çš„ä»…è§£ç å™¨ï¼ˆDecoder-Onlyï¼‰æ¨¡å¼ï¼Œç”¨äºæ–‡æœ¬ç”Ÿæˆã€‚
  - **åºåˆ—åˆ°åºåˆ— (Sequence-to-Sequence)**: å®Œæ•´çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆEncoder-Decoderï¼‰æ¶æ„ï¼Œç”¨äºæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ã€‚
  - **æ–‡æœ¬åˆ†ç±» (Text Classification)**: ï¼ˆéœ€åœ¨æ¨¡å‹ä¸­æ·»åŠ åˆ†ç±»å¤´ï¼‰æ•°æ®åŠ è½½æµç¨‹å·²æ”¯æŒã€‚
- **å¯é…ç½®**: é€šè¿‡ `src/config.py` æ–‡ä»¶å¯ä»¥è½»æ¾å®šä¹‰å’Œåˆ‡æ¢ä¸åŒçš„æ¨¡å‹è¶…å‚æ•°ã€æ•°æ®é›†å’Œè®­ç»ƒè®¾ç½®ã€‚
- **é«˜çº§è®­ç»ƒç‰¹æ€§**:
  - æ”¯æŒä»æ£€æŸ¥ç‚¹**æ¢å¤è®­ç»ƒ**ã€‚
  - é›†æˆ **Cosine Annealing å­¦ä¹ ç‡è°ƒåº¦å™¨**ã€‚
  - è‡ªåŠ¨å°†è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡ï¼ˆLoss, Perplexity, Learning Rateï¼‰è®°å½•åˆ° `training_metrics.csv`ã€‚
- **æ–‡æœ¬ç”Ÿæˆ**: `eval.py` è„šæœ¬æ”¯æŒä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¹¶é›†æˆäº†**æ¸©åº¦ï¼ˆTemperatureï¼‰**å’Œ **Top-K é‡‡æ ·**ç­–ç•¥ã€‚
- **ç»“æœå¯è§†åŒ–**: `results/plot_metrics.py` è„šæœ¬å¯ä»¥ä¸€é”®å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡ç»˜åˆ¶æˆå›¾è¡¨ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ data/                     # (å»ºè®®) å­˜æ”¾æœ¬åœ°æ•°æ®é›†
â”‚   â””â”€â”€ tinyshakespeare.txt
â”œâ”€â”€ results/                  # å­˜æ”¾ç»“æœå’Œå›¾è¡¨
â”‚   â”œâ”€â”€ plot_metrics.py       # ç»˜å›¾è„šæœ¬
â”‚   â””â”€â”€ training_curves.png   # ç”Ÿæˆçš„å›¾è¡¨
â”œâ”€â”€ src/                      # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ config.py             # ä»»åŠ¡å’Œæ¨¡å‹é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ dataset_utils.py      # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”‚   â””â”€â”€ model.py              # Transformer æ¨¡å‹å®šä¹‰
â”œâ”€â”€ train.py                  # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ eval.py                   # è¯„ä¼°å’Œæ–‡æœ¬ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ best_model_checkpoint.pt  # è®­ç»ƒä¸­ä¿å­˜çš„æœ€ä½³æ¨¡å‹
â”œâ”€â”€ training_metrics.csv      # è®­ç»ƒæŒ‡æ ‡æ—¥å¿—
â””â”€â”€ requirements.txt          # é¡¹ç›®ä¾èµ–
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®

é¦–å…ˆï¼Œå…‹éš†æœ¬ä»“åº“å¹¶è¿›å…¥é¡¹ç›®ç›®å½•ï¼š
```bash
git clone <your-repo-url>
cd transformer-project
```

å»ºè®®ä½¿ç”¨ Conda æˆ– venv åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ Python ç¯å¢ƒï¼š
```bash
# ä½¿ç”¨ Conda
conda create -n transformer_env python=3.8
conda activate transformer_env

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate    # Windows
```

ç„¶åï¼Œå®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–é¡¹ï¼š
```bash
pip install -r requirements.txt
```

### 2. è®­ç»ƒæ¨¡å‹

ä½¿ç”¨ `train.py` è„šæœ¬å¼€å§‹è®­ç»ƒã€‚ä½ å¯ä»¥é€šè¿‡ `--config` å‚æ•°é€‰æ‹©ä¸€ä¸ªé¢„å®šä¹‰çš„é…ç½®ï¼ˆä¾‹å¦‚ `tiny_shakespeare`ï¼‰ã€‚

**å¼€å§‹ä¸€æ¬¡æ–°è®­ç»ƒ:**
```bash
# åœ¨ç¬¬ä¸€ä¸ªå¯ç”¨ GPU ä¸Šè®­ç»ƒ
python train.py --config tiny_shakespeare
```

**æŒ‡å®š GPU å¹¶è®¾ç½®æ€»è½®æ¬¡:**
```bash
# åœ¨ 1 å· GPU ä¸Šè®­ç»ƒ 200 è½®
CUDA_VISIBLE_DEVICES=1 python train.py --config tiny_shakespeare --epochs 200
```

**ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ:**
```bash
CUDA_VISIBLE_DEVICES=1 python train.py --config tiny_shakespeare --resume --epochs 300
```

### 3. è¯„ä¼°ä¸æ–‡æœ¬ç”Ÿæˆ

è®­ç»ƒå®Œæˆåï¼Œ`best_model_checkpoint.pt` æ–‡ä»¶ä¼šè¢«ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ã€‚è¿è¡Œ `eval.py` æ¥åŠ è½½æ¨¡å‹å¹¶ç”Ÿæˆæ–‡æœ¬ã€‚
```bash
python eval.py
```
ä½ å¯ä»¥ç›´æ¥åœ¨ `eval.py` è„šæœ¬çš„ `if __name__ == "__main__"` éƒ¨åˆ†ä¿®æ”¹èµ·å§‹æ–‡æœ¬ã€ç”Ÿæˆé•¿åº¦å’Œé‡‡æ ·å‚æ•°ã€‚

### 4. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

è¿è¡Œ `plot_metrics.py` è„šæœ¬æ¥å°† `training_metrics.csv` ä¸­çš„æ•°æ®ç»˜åˆ¶æˆå›¾è¡¨ã€‚
```bash
python results/plot_metrics.py
```
ç”Ÿæˆçš„ `training_curves.png` å›¾åƒå°†è¢«ä¿å­˜åœ¨ `results/` ç›®å½•ä¸‹ã€‚

## ğŸ”§ é¢„ç½®é…ç½®

é¡¹ç›®ä¸­é¢„ç½®äº†ä»¥ä¸‹é…ç½®ï¼Œå¯åœ¨ `src/config.py` ä¸­æŸ¥çœ‹å’Œä¿®æ”¹ï¼š

- `tiny_shakespeare`: ç”¨äºå­—ç¬¦çº§è¯­è¨€å»ºæ¨¡ã€‚
- `iwslt2017`: ç”¨äºè‹±å¾·æœºå™¨ç¿»è¯‘ã€‚
- `ag_news`: ç”¨äºæ–°é—»æ–‡æœ¬åˆ†ç±»ã€‚
```

---

### `requirements.txt`

è¿™ä¸ªæ–‡ä»¶åˆ—å‡ºäº†é¡¹ç›®è¿è¡Œæ‰€éœ€çš„æ‰€æœ‰ Python åº“ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ `pip install -r requirements.txt` ä¸€é”®å®‰è£…ã€‚

````text
// filepath: f:\transformer-project\requirements.txt
# Core deep learning framework
torch
torchvision
torchaudio

# Hugging Face libraries for datasets and tokenizers
datasets
transformers

# Utilities
tqdm         # Progress bars
requests     # For downloading data if needed

# For plotting results
pandas
matplotlib
